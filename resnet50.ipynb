{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Flatten ,Dense , MaxPool2D , BatchNormalization , GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input , decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator , load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f510322c019f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_height\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"224,224\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_data_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\paradaise\\Desktop\\flower\\test\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvalid_data_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\paradaise\\Desktop\\flower\\train\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_data_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\paradaise\\Desktop\\flower\\val\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "img_height , img_width = \"224,224\"\n",
    "batch_size = 32\n",
    "train_data_dir = r\"C:\\Users\\paradaise\\Desktop\\flower\\test\"\n",
    "valid_data_dir = r\"C:\\Users\\paradaise\\Desktop\\flower\\train\"\n",
    "test_data_dir = r\"C:\\Users\\paradaise\\Desktop\\flower\\val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataGenerator' object has no attribute 'flow_from_dierectory'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-51ff1dac1c4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                   \u001b[0mhorizontal_flip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   validation_split = 0.4)\n\u001b[1;32m----> 6\u001b[1;33m train_generator = train_datagen.flow_from_dierectory(\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_data_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_height\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDataGenerator' object has no attribute 'flow_from_dierectory'"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input, \n",
    "                                  shear_range = 0.2 , \n",
    "                                  zoom_range  = 0.2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  validation_split = 0.4)\n",
    "train_generator = train_datagen.flow_from_dierectory(\n",
    "train_data_dir,\n",
    "target_size = (img_height , img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"categorical\",\n",
    "    subset = \"training\") # set as training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataGenerator' object has no attribute 'flow_from_dierectory'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-823c69a640fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m test_generator = train_datagen.flow_from_dierectory(\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_data_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#same directory as training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclass_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"categorical\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m subset = \"validation\") # set as validation data \n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDataGenerator' object has no attribute 'flow_from_dierectory'"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_dierectory(\n",
    "test_data_dir, #same directory as training data\n",
    "target_size = 1,\n",
    "class_mode = \"categorical\" , \n",
    "subset = \"validation\") # set as validation data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f4990194f8a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_generator' is not defined"
     ]
    }
   ],
   "source": [
    "x, y = test_generator.next()\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-fa03a3cd4065>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-fa03a3cd4065>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    model = Model(inputs = base_model.input , output , =predictions)\u001b[0m\n\u001b[1;37m                                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "base_model = Resnet50(include_top = False , weights = \"imagenet\")\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024 , activation = \"relu\")(x)\n",
    "predictions = Dense(train_generator.num_classes , activation = \"softmax\")(x)\n",
    "model = Model(inputs = base_model.input , output , =predictions)\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer = \"adam\" , loss = \"categorical_crossentropy\" , metrics = [\"accuracy\"])\n",
    "model.fit(train_generator,epochs = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f90cb040f7f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss , test_acc = modelevaluate(test_generator , verbose = 2)\n",
    "print(\"\\nTest accuracy\" , test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(\"\")\n",
    "filenames = test_generator.filenames\n",
    "nb_samples = len(test_generator)\n",
    "y_prob = []\n",
    "y_act = []\n",
    "test_generator.reset()\n",
    "for _ in range(nb_samples):\n",
    "    x_test , Y_test = test_generator.next()\n",
    "    y_prob.append(model.predict(x_test))\n",
    "    y_act.append(Y_test)\n",
    "    \n",
    "    \n",
    "predicted_class = [list(train_generator.class_indices.keys())[i.argmax() for i in y_prob]]\n",
    "actual_class = [list(train_generator.class_indices.keys())][i.argmax() for i in y_act]\n",
    "\n",
    "\n",
    "out_df = pd.DataFrame(np.vstack([predicted_class , actual_class])).T,columns = [\"predicted_class\" , \"actual_class\"]\n",
    "confusion_matrix = pd.crosstab(out_df[\"actual_class\"] , out_df[\"predicted_class\"] , rownames = [\"actual\"] , colnames = [\"predicted\"])\n",
    "sns.heatmap(confusion_matrix , cmap = \"Blues\" , annot = True , fmt = \"d\")\n",
    "print(\"test accuracy : {}\".format((np.diagonal(confusion_matrix).sum() / confusion_matrix.sum().sum() * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
